server.port=8080
server.servlet.context-path=/project-archetype

mybatis.mapperLocations=classpath:mybatis/mappers/*.xml
# mybatis 是否开启全局二级缓存
mybatis.configuration.cache-enabled=false 

spring.datasource.url=jdbc:mysql://192.168.2.201:3306/wr1ttenyu
spring.datasource.username=root
spring.datasource.password=p@ssword
spring.datasource.driver-class-name=com.mysql.jdbc.Driver

# Redis数据库索引（默认为0）TODO REDIS 数据库索引的作用
spring.redis.database=0
spring.redis.host=122.51.219.124
spring.redis.port=6379
spring.redis.password=A@awr1ttenyu
spring.redis.timeout=PT1000S

#kafka
spring.kafka.bootstrap-servers=127.0.0.1:9092 
#producer
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#配置控制了KafkaProducer.send()并将KafkaProducer.partitionsFor()被阻塞多长时间。
# 由于缓冲区已满或元数据不可用，这些方法可能会被阻塞止。用户提供的序列化程序或分区程序中的阻塞将不计入此超时。
spring.kafka.producer.max.block.ms=1000

#consumer
spring.kafka.consumer.group-id=default_consumer_group 
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#是否开启自动提交
spring.kafka.consumer.enable-auto-commit=true
#自动提交时间间隔
spring.kafka.consumer.auto-commit-interval=1000
#消费者offset重置策略 latest 每次重新连接后 从上次消费的地方接着消费
spring.kafka.consumer.auto-offset-reset=latest
#fetch时最小拉取的字节数
spring.kafka.consumer.fetch-min-size=1


spring.kafka.consumer.max-poll-records=
#The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.
spring.kafka.consumer.receive.buffer.bytes=

fetch.max.bytes



logging.level.wr1ttenyu.f1nal.study.project.archetype.dao.UUserMapper=debug